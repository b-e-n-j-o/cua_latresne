"""
llm_utils.py ‚Äî Utilitaires pour l'appel des LLMs OpenAI
"""

import os
import json
import logging
import base64
from typing import Dict, Any
from openai import OpenAI

logger = logging.getLogger(__name__)

import dotenv
dotenv.load_dotenv()

# Configuration OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def extract_text_from_response(response) -> str:
    """
    Extraction robuste du texte depuis la r√©ponse OpenAI.
    Couvre tous les formats possibles du SDK 'responses'.
    """
    
    # 1) helper universel du SDK responses (s'il existe)
    if hasattr(response, "output_text") and response.output_text:
        logger.info("‚úÖ Texte extrait via response.output_text")
        return response.output_text

    # 2) format "responses": output -> content -> text.value
    try:
        parts = []
        for item in getattr(response, "output", []) or []:
            for c in getattr(item, "content", []) or []:
                # certains SDK mettent text.value, d'autres text
                if hasattr(c, "text") and c.text:
                    val = getattr(c.text, "value", None) or c.text
                    if isinstance(val, str):
                        parts.append(val)
        if parts:
            logger.info(f"‚úÖ Texte extrait via response.output[].content[].text ({len(parts)} parties)")
            return "".join(parts)
    except Exception as e:
        logger.debug(f"Tentative d'extraction via output[] √©chou√©e: {e}")

    # 3) fallback pour anciens formats (chat.completions-like)
    if hasattr(response, "choices"):
        try:
            text = response.choices[0].message.content
            if text:
                logger.info("‚úÖ Texte extrait via response.choices[0].message.content")
                return text
        except Exception as e:
            logger.debug(f"Tentative d'extraction via choices √©chou√©e: {e}")

    # 4) dernier recours : essayer d'acc√©der directement aux attributs
    for attr in ["content", "text", "message", "response"]:
        try:
            if hasattr(response, attr):
                val = getattr(response, attr)
                if isinstance(val, str) and val.strip():
                    logger.info(f"‚úÖ Texte extrait via response.{attr}")
                    return val.strip()
        except Exception:
            continue

    logger.error("‚ùå Aucune m√©thode d'extraction n'a fonctionn√©")
    return ""

def call_gpt5_text(prompt: str, reasoning_effort: str = "medium", verbosity: str = "medium") -> Dict[str, Any]:
    """
    Appel de l'API GPT-5 via le format 'responses'.
    Retourne un dict avec success, response, et error si applicable.
    """
    
    logger.info(f"üìù Appel API GPT-5 - Texte uniquement (reasoning: {reasoning_effort}, verbosity: {verbosity})")
    
    try:
        # V√©rification de la cl√© API
        if not os.getenv("OPENAI_API_KEY"):
            return {
                "success": False, 
                "error": "OPENAI_API_KEY manquant dans l'environnement"
            }
        
        # Appel API avec format 'responses'
        response = client.responses.create(
            model="gpt-5",
            input=[{"role": "user", "content": prompt}],   # ‚úÖ format messages
            reasoning={"effort": reasoning_effort},
            text={"verbosity": verbosity}
        )
        
        # Extraction du texte
        output_text = extract_text_from_response(response)
        
        if not output_text:
            return {
                "success": False,
                "error": "R√©ponse re√ßue mais texte non extractible",
                "raw_response": str(response)
            }
        
        logger.info(f"‚úÖ R√©ponse re√ßue ({len(output_text)} caract√®res)")
        
        # Affichage des tokens si disponibles
        if hasattr(response, 'usage') and response.usage:
            usage = response.usage
            logger.info(f"üí∞ Tokens utilis√©s:")
            logger.info(f"  - Input tokens: {getattr(usage, 'input_tokens', 'N/A')}")
            if hasattr(usage, 'input_tokens_details') and usage.input_tokens_details:
                logger.info(f"    - Cached tokens: {getattr(usage.input_tokens_details, 'cached_tokens', 'N/A')}")
            logger.info(f"  - Output tokens: {getattr(usage, 'output_tokens', 'N/A')}")
            if hasattr(usage, 'output_tokens_details') and usage.output_tokens_details:
                logger.info(f"    - Reasoning tokens: {getattr(usage.output_tokens_details, 'reasoning_tokens', 'N/A')}")
            logger.info(f"  - Total tokens: {getattr(usage, 'total_tokens', 'N/A')}")
        
        return {
            "success": True, 
            "response": output_text, 
            "raw_response": response
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'appel API: {e}")
        return {
            "success": False, 
            "error": str(e)
        }

def call_gpt4o_text(prompt: str, max_tokens: int = 20000) -> Dict[str, Any]:
    """
    Fallback vers GPT-4o si GPT-5 n'est pas disponible.
    """
    
    logger.info(f"üìù Appel API GPT-4o - Fallback (max_tokens: {max_tokens})")
    
    try:
        if not os.getenv("OPENAI_API_KEY"):
            return {
                "success": False, 
                "error": "OPENAI_API_KEY manquant dans l'environnement"
            }
        
        # Appel classique chat completions
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=max_tokens,
            temperature=0.1
        )
        
        output_text = response.choices[0].message.content
        
        if not output_text:
            return {
                "success": False,
                "error": "R√©ponse GPT-4o vide"
            }
        
        logger.info(f"‚úÖ R√©ponse GPT-4o re√ßue ({len(output_text)} caract√®res)")
        
        # Affichage des tokens si disponibles
        if hasattr(response, 'usage') and response.usage:
            usage = response.usage
            logger.info(f"üí∞ Tokens GPT-4o utilis√©s:")
            logger.info(f"  - Input tokens: {getattr(usage, 'prompt_tokens', 'N/A')}")
            logger.info(f"  - Output tokens: {getattr(usage, 'completion_tokens', 'N/A')}")
            logger.info(f"  - Total tokens: {getattr(usage, 'total_tokens', 'N/A')}")
        
        return {
            "success": True,
            "response": output_text,
            "raw_response": response
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'appel GPT-4o: {e}")
        return {
            "success": False, 
            "error": str(e)
        }

def call_gpt4o_json(prompt: str, temperature: float = 0.1) -> Dict[str, Any]:
    """
    Appel GPT-4o via chat.completions avec for√ßage de JSON valide.
    Retourne un dict avec success, response (JSON pars√©), et error si applicable.
    """
    logger.info("ü§ñ Appel API GPT-4o (chat.completions) - force JSON")
    
    try:
        # V√©rification de la cl√© API
        if not os.getenv("OPENAI_API_KEY"):
            return {
                "success": False, 
                "error": "OPENAI_API_KEY manquant dans l'environnement"
            }
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=temperature
        )
        
        json_text = response.choices[0].message.content
        
        if not json_text:
            return {
                "success": False,
                "error": "R√©ponse GPT-4o JSON vide"
            }
        
        # Parsing du JSON
        try:
            parsed_json = json.loads(json_text)
            logger.info(f"‚úÖ JSON GPT-4o re√ßu et pars√© ({len(json_text)} caract√®res)")
            
            # Affichage des tokens si disponibles
            if hasattr(response, 'usage') and response.usage:
                usage = response.usage
                logger.info(f"üí∞ Tokens GPT-4o JSON utilis√©s:")
                logger.info(f"  - Input tokens: {getattr(usage, 'prompt_tokens', 'N/A')}")
                logger.info(f"  - Output tokens: {getattr(usage, 'completion_tokens', 'N/A')}")
                logger.info(f"  - Total tokens: {getattr(usage, 'total_tokens', 'N/A')}")
            
            return {
                "success": True,
                "response": parsed_json,  # JSON d√©j√† pars√©
                "raw_response": response,
                "json_text": json_text  # Texte JSON brut aussi disponible
            }
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå JSON GPT-4o invalide: {e}")
            return {
                "success": False,
                "error": f"JSON invalide: {e}",
                "raw_response": response,
                "json_text": json_text
            }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur GPT-4o JSON: {e}")
        return {
            "success": False, 
            "error": str(e)
        }

def call_gpt5_json(prompt: str, temperature: float = 0.1) -> Dict[str, Any]:
    """
    Appel GPT-5 via chat.completions avec for√ßage de JSON valide.
    Retourne un dict avec success, response (JSON pars√©), et error si applicable.
    """
    logger.info("ü§ñ Appel API GPT-5 (chat.completions) - force JSON")
    
    try:
        # V√©rification de la cl√© API
        if not os.getenv("OPENAI_API_KEY"):
            return {
                "success": False, 
                "error": "OPENAI_API_KEY manquant dans l'environnement"
            }
        
        response = client.chat.completions.create(
            model="gpt-5",  # ou "gpt-5" selon disponibilit√©
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        
        json_text = response.choices[0].message.content
        
        if not json_text:
            return {
                "success": False,
                "error": "R√©ponse GPT-5 JSON vide"
            }
        
        # Parsing du JSON
        try:
            parsed_json = json.loads(json_text)
            logger.info(f"‚úÖ JSON GPT-5 re√ßu et pars√© ({len(json_text)} caract√®res)")
            
            # Affichage des tokens si disponibles
            if hasattr(response, 'usage') and response.usage:
                usage = response.usage
                logger.info(f"üí∞ Tokens GPT-5 JSON utilis√©s:")
                logger.info(f"  - Input tokens: {getattr(usage, 'prompt_tokens', 'N/A')}")
                logger.info(f"  - Output tokens: {getattr(usage, 'completion_tokens', 'N/A')}")
                logger.info(f"  - Total tokens: {getattr(usage, 'total_tokens', 'N/A')}")
            
            return {
                "success": True,
                "response": parsed_json,  # JSON d√©j√† pars√©
                "raw_response": response,
                "json_text": json_text  # Texte JSON brut aussi disponible
            }
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå JSON GPT-5 invalide: {e}")
            return {
                "success": False,
                "error": f"JSON invalide: {e}",
                "raw_response": response,
                "json_text": json_text
            }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur GPT-5 JSON: {e}")
        return {
            "success": False, 
            "error": str(e)
        }

def call_gpt4o_vision(image_bytes: bytes, prompt: str = "Extrait le texte brut lisible de ce document. Ne renvoie que le texte, sans ajout.", temperature: float = 0.0) -> Dict[str, Any]:
    """
    Appel API GPT-4o avec une image (vision) pour extraire du texte.

    Args:
        image_bytes (bytes): Contenu binaire de l'image (PNG/JPEG)
        prompt (str): Instruction utilisateur
        temperature (float): Cr√©ativit√©

    Returns:
        Dict: {success, response (texte), raw_response}
    """
    logger.info(f"üñºÔ∏è Appel API GPT-4o Vision (temperature: {temperature})")

    try:
        # V√©rification de la cl√© API
        if not os.getenv("OPENAI_API_KEY"):
            return {
                "success": False, 
                "error": "OPENAI_API_KEY manquant dans l'environnement"
            }

        b64 = base64.b64encode(image_bytes).decode("ascii")
        data_url = f"data:image/png;base64,{b64}"

        api_params = {
            "model": "gpt-4o",
            "input": [
                {
                    "role": "user",
                    "content": [
                        {"type": "input_text", "text": prompt},
                        {"type": "input_image", "image_url": data_url},
                    ],
                }
            ],
            "temperature": temperature,
        }

        response = client.responses.create(**api_params)
        output_text = extract_text_from_response(response)
        logger.info("‚úÖ R√©ponse vision re√ßue avec succ√®s")
        
        # Affichage des tokens si disponibles
        if hasattr(response, 'usage') and response.usage:
            usage = response.usage
            logger.info(f"üí∞ Tokens GPT-4o Vision utilis√©s:")
            logger.info(f"  - Input tokens: {getattr(usage, 'input_tokens', 'N/A')}")
            if hasattr(usage, 'input_tokens_details') and usage.input_tokens_details:
                logger.info(f"    - Cached tokens: {getattr(usage.input_tokens_details, 'cached_tokens', 'N/A')}")
            logger.info(f"  - Output tokens: {getattr(usage, 'output_tokens', 'N/A')}")
            if hasattr(usage, 'output_tokens_details') and usage.output_tokens_details:
                logger.info(f"    - Reasoning tokens: {getattr(usage.output_tokens_details, 'reasoning_tokens', 'N/A')}")
            logger.info(f"  - Total tokens: {getattr(usage, 'total_tokens', 'N/A')}")
        
        return {"success": True, "response": output_text, "raw_response": response}

    except Exception as e:
        logger.error(f"‚ùå Erreur vision: {e}")
        return {"success": False, "error": str(e)}

# Test rapide si ex√©cut√© directement
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    # Test de la configuration
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        logger.info(f"‚úÖ OPENAI_API_KEY configur√© ({len(api_key)} caract√®res)")
    else:
        logger.warning("‚ö†Ô∏è OPENAI_API_KEY non configur√©")
    
    # Test d'appel simple
    test_prompt = "Dis-moi bonjour en une phrase."
    logger.info("üß™ Test d'appel API...")
    
    result = call_gpt5_text(test_prompt)
    if result["success"]:
        logger.info(f"‚úÖ Test r√©ussi: {result['response'][:50]}...")
    else:
        logger.warning(f"‚ö†Ô∏è Test GPT-5 √©chou√©: {result['error']}")
        # Fallback GPT-4o
        result_fallback = call_gpt4o_text(test_prompt)
        if result_fallback["success"]:
            logger.info(f"‚úÖ Fallback GPT-4o r√©ussi: {result_fallback['response'][:50]}...")
        else:
            logger.error(f"‚ùå Fallback GPT-4o aussi √©chou√©: {result_fallback['error']}")
    
    # Test des nouvelles fonctions JSON
    logger.info("üß™ Test des fonctions JSON...")
    
    json_prompt = 'Cr√©e un objet JSON avec les cl√©s "nom" et "age". Exemple: {"nom": "Jean", "age": 30}'
    
    # Test GPT-4o JSON
    result_json_4o = call_gpt4o_json(json_prompt)
    if result_json_4o["success"]:
        logger.info(f"‚úÖ GPT-4o JSON r√©ussi: {result_json_4o['response']}")
    else:
        logger.warning(f"‚ö†Ô∏è GPT-4o JSON √©chou√©: {result_json_4o['error']}")
    
    # Test GPT-5 JSON
    result_json_5 = call_gpt5_json(json_prompt)
    if result_json_5["success"]:
        logger.info(f"‚úÖ GPT-5 JSON r√©ussi: {result_json_5['response']}")
    else:
        logger.warning(f"‚ö†Ô∏è GPT-5 JSON √©chou√©: {result_json_5['error']}")
    
    # Test GPT-4o Vision (simulation avec bytes vides)
    logger.info("üß™ Test GPT-4o Vision...")
    try:
        # Simulation d'une image (bytes vides pour le test)
        test_image = b"fake_image_data"
        result_vision = call_gpt4o_vision(test_image, "Test de vision")
        if result_vision["success"]:
            logger.info(f"‚úÖ GPT-4o Vision r√©ussi: {result_vision['response'][:50]}...")
        else:
            logger.warning(f"‚ö†Ô∏è GPT-4o Vision √©chou√©: {result_vision['error']}")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Test Vision √©chou√© (normal sans vraie image): {e}")
